# awesome-ai

<<fill>>

## Latest Developments

This repository explores the concept of an escalation function, denoted as "e()", within the context of Large Language Models (LLMs). The idea is to enhance LLMs by incorporating a layered architecture and an escalation mechanism that allows a core LLM to delegate tasks to an outer layer with extended capabilities.

## Repository Structure

The repository is organized into several folders, each representing a different aspect of the project:

- **Eurus:** Contains 'solutions' generated by the Eurus model, reasoning about the very complex multi-persona chat logs.
- **FizzEase:** Contains prompts, topics, and settings related to the FizzEase AI assistant, which also explores the concept of e() as a signaling mechanism.
- **Fizz La Metta:** Contains metrics, prompts, and functions related to the Fizz La Metta AI assistant, which focuses on meta-artificial intelligence tasks.
- **KickBuzz:** Contains topics, prompts, and functions related to the KickBuzz AI assistant, which specializes in rules-based content generation.
- **Kick La Metta:** Contains functions, prompts, and queries related to the Kick La Metta AI assistant, which is a senior agent in meta-artificial intelligence tasks.
- **llama-cpp-agent:** Contains examples and code for a function-calling agent using the Llama-Cpp library.
- **MultiMax:** Contains queries, prompts, and topics related to the MultiMax AI assistant, which acts as an actor and spokesperson for the system.
- **ntfy.violass.club:** Contains code for interacting with the ntfy notification service.
- **papers:** Contains drafts and outlines for scientific papers exploring the e() function and layered LLM architectures.
- **pi.ai:** Contains transcripts and outputs from interactions with the pi.ai personal AI assistant.
- **src:** Contains source code for various components of the project, including a PyQt5 application for interacting with LLMs.

## Licensing

This repository is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Disclaimer

This repository is for research and exploration purposes only. The code and concepts presented here are not intended for production use. The authors make no warranties or guarantees about the accuracy, completeness, or suitability of the information provided.

## External Resources

This project utilizes several external resources, including:

- **Ollama:** An open-source tool for running large language models locally. [https://ollama.ai/](https://ollama.ai/)
- **OpenAI API:** A cloud-based platform for accessing and using large language models. [https://platform.openai.com/](https://platform.openai.com/)
- **Llama-Cpp:** A C++ library for running large language models locally. [https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)
- **PyQt5:** A Python binding for the Qt application framework. [https://pypi.org/project/PyQt5/](https://pypi.org/project/PyQt5/)
- **ntfy:** A simple notification service. [https://ntfy.sh/](https://ntfy.sh/)
- **pi.ai:** A personal AI assistant. [https://pi.ai/](https://pi.ai/)
- **Cohere AI:** A platform for building and deploying large language models. [https://cohere.ai/](https://cohere.ai/)

Please refer to the documentation of these resources for more information.
